#!/usr/bin/env python3
"""
è©•ä¾¡ãƒ»æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«ä»˜ã6æ®µéšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡¦ç†ã§JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰Q&Aãƒšã‚¢ã‚’ç”Ÿæˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é«˜å“è³ªãªQ&Aãƒšã‚¢ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã«ã€
6ã¤ã®å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ï¼š

1. Q&Aç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: åŸºæœ¬çš„ãªè³ªå•-å›ç­”ãƒšã‚¢ã‚’ç”Ÿæˆ
2. Q&Aè©•ä¾¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: ç”Ÿæˆã•ã‚ŒãŸQ&Aã®å“è³ªã‚’è©•ä¾¡
3. Q&Aæ”¹å–„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: è©•ä¾¡ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«åŸºã¥ã„ã¦Q&Aã‚’æ”¹å–„
4. ãƒšãƒ«ã‚½ãƒŠåˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: è³ªå•è€…ã®ãƒšãƒ«ã‚½ãƒŠã‚’ç‰¹å®š
5. ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: æƒ…å ±ã‚«ãƒ†ã‚´ãƒªã‚’åˆ†é¡
6. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º

å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ç‰¹å®šã®å°‚é–€åˆ†é‡ã«é›†ä¸­ã—ã€é«˜å“è³ªãªçµæœã‚’æä¾›ã—ã¾ã™ã€‚
è©•ä¾¡ãƒ»æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«ã«ã‚ˆã‚Šã€è‡ªå‹•çš„ã«Q&Aã®å“è³ªå‘ä¸Šã‚’å›³ã‚Šã¾ã™ã€‚
"""
import asyncio
import jsonlines
import os
import argparse
import threading
from typing import List, Set, Tuple, Dict, Any, Optional
from pydantic import BaseModel
from dotenv import load_dotenv
from enum import Enum

from agents import Agent, Runner # agentsãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰Agentã¨Runnerã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

load_dotenv("/app/.env", override=True)

# --- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šç®¡ç†ã‚¯ãƒ©ã‚¹ ---
class AgentConfig:
    """å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å€‹åˆ¥è¨­å®šã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, base_model: str = "gpt-4o-mini"):
        self.base_model = base_model
        
        # å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å€‹åˆ¥è¨­å®š
        self.agents = {
            "qa_generation": {
                "model": "gpt-4o",  # é«˜å“è³ªãŒå¿…è¦ãªã®ã§ã‚ˆã‚Šæ€§èƒ½ã®é«˜ã„ãƒ¢ãƒ‡ãƒ«
                "temperature": 0.7,  # å‰µé€ æ€§ã‚’å°‘ã—é«˜ã‚ã‚‹
                "max_tokens": 1000,
                "timeout": 60
            },
            "qa_evaluation": {
                "model": "gpt-4o",  # è©•ä¾¡ã®ä¸€è²«æ€§ã®ãŸã‚é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«
                "temperature": 0.3,  # è©•ä¾¡ã®ä¸€è²«æ€§ã®ãŸã‚ä½æ¸©åº¦
                "max_tokens": 800,
                "timeout": 45
            },
            "qa_improvement": {
                "model": "gpt-4o",  # æ”¹å–„ã«ã¯è¤‡é›‘ãªæ¨è«–ãŒå¿…è¦
                "temperature": 0.5,  # ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸå‰µé€ æ€§
                "max_tokens": 1000,
                "timeout": 60
            },
            "persona_analysis": {
                "model": "gpt-4o-mini",  # åˆ†é¡ã‚¿ã‚¹ã‚¯ãªã®ã§åŠ¹ç‡çš„ãªãƒ¢ãƒ‡ãƒ«
                "temperature": 0.2,  # åˆ†é¡ã®ä¸€è²«æ€§ã®ãŸã‚ä½æ¸©åº¦
                "max_tokens": 200,
                "timeout": 30
            },
            "category_analysis": {
                "model": "gpt-4o-mini",  # åˆ†é¡ã‚¿ã‚¹ã‚¯ãªã®ã§åŠ¹ç‡çš„ãªãƒ¢ãƒ‡ãƒ«
                "temperature": 0.2,  # åˆ†é¡ã®ä¸€è²«æ€§ã®ãŸã‚ä½æ¸©åº¦
                "max_tokens": 200,
                "timeout": 30
            },
            "keyword_extraction": {
                "model": "gpt-4o-mini",  # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã¯åŠ¹ç‡çš„ãªãƒ¢ãƒ‡ãƒ«ã§ååˆ†
                "temperature": 0.1,  # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã®ä¸€è²«æ€§ã®ãŸã‚æœ€ä½æ¸©åº¦
                "max_tokens": 300,
                "timeout": 30
            }
        }
    
    def get_agent_config(self, agent_name: str) -> Dict[str, Any]:
        """æŒ‡å®šã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨­å®šã‚’å–å¾—"""
        return self.agents.get(agent_name, {
            "model": self.base_model,
            "temperature": 0.5,
            "max_tokens": 500,
            "timeout": 30
        })
    
    def set_agent_model(self, agent_name: str, model: str):
        """ç‰¹å®šã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®š"""
        if agent_name in self.agents:
            self.agents[agent_name]["model"] = model
    
    def set_agent_temperature(self, agent_name: str, temperature: float):
        """ç‰¹å®šã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®temperatureã‚’è¨­å®š"""
        if agent_name in self.agents:
            self.agents[agent_name]["temperature"] = temperature
    
    def set_quality_mode(self, mode: str):
        """å“è³ªãƒ¢ãƒ¼ãƒ‰ã‚’è¨­å®šï¼ˆall_premium, all_standard, balancedï¼‰"""
        if mode == "all_premium":
            # ã™ã¹ã¦æœ€é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«
            for agent_name in self.agents:
                self.agents[agent_name]["model"] = "gpt-4o"
        elif mode == "all_standard":
            # ã™ã¹ã¦æ¨™æº–ãƒ¢ãƒ‡ãƒ«
            for agent_name in self.agents:
                self.agents[agent_name]["model"] = "gpt-4o-mini"
        elif mode == "balanced":
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šï¼ˆé‡è¦ãªã‚¿ã‚¹ã‚¯ã®ã¿é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ï¼‰
            pass  # æ—¢ã«ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šæ¸ˆã¿
    
    def print_config(self):
        """ç¾åœ¨ã®è¨­å®šã‚’è¡¨ç¤º"""
        print("ğŸ”§ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®š:")
        for agent_name, config in self.agents.items():
            print(f"  {agent_name}: {config['model']} (temp: {config['temperature']}, max_tokens: {config['max_tokens']})")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®šã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
agent_config = AgentConfig()

# --- ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ« ---
class EvaluationScore(str, Enum):
    EXCELLENT = "excellent"  # 90-100ç‚¹
    GOOD = "good"           # 70-89ç‚¹  
    FAIR = "fair"           # 50-69ç‚¹
    POOR = "poor"           # 0-49ç‚¹

class BasicQAPair(BaseModel):
    """åŸºæœ¬çš„ãªQ&Aãƒšã‚¢ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰"""
    question: str
    answer: str
    source_url: str

class PersonaResult(BaseModel):
    """ãƒšãƒ«ã‚½ãƒŠåˆ†æçµæœ"""
    questioner_persona: str

class CategoryResult(BaseModel):
    """ã‚«ãƒ†ã‚´ãƒªåˆ†æçµæœ"""
    information_category: str

class KeywordsResult(BaseModel):
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æçµæœ"""
    related_keywords: List[str]

class QAEvaluation(BaseModel):
    """Q&Aè©•ä¾¡çµæœ"""
    overall_score: int  # 0-100ç‚¹
    overall_rating: EvaluationScore
    
    # è©•ä¾¡é …ç›®åˆ¥ã‚¹ã‚³ã‚¢
    source_coverage_score: int      # å…ƒã‚½ãƒ¼ã‚¹ã«å›ç­”æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ (0-100)
    question_specificity_score: int # è³ªå•ãŒååˆ†ã«èƒŒæ™¯æƒ…å ±ã‚’å«ã‚€ã‹ (0-100)
    condition_clarity_score: int    # æ¡ä»¶ãŒæ˜ç¢ºã«ç¤ºã•ã‚Œã¦ã„ã‚‹ã‹ (0-100)
    
    # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
    strengths: List[str]           # è‰¯ã„ç‚¹
    improvement_areas: List[str]   # æ”¹å–„ç‚¹
    specific_suggestions: List[str] # å…·ä½“çš„ãªæ”¹å–„ææ¡ˆ
    
    # æ”¹å–„ã®å¿…è¦æ€§
    needs_improvement: bool
    improvement_priority: str  # "high", "medium", "low"

class QAPair(BaseModel):
    """å®Œå…¨ãªQ&Aãƒšã‚¢ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ãï¼‰"""
    question: str
    answer: str
    source_url: str # JSONLã®å„ã‚¨ãƒ³ãƒˆãƒªã®å‡ºå…¸ã‚’ç¤ºã™ãŸã‚ã«æµç”¨
    questioner_persona: str # è¿½åŠ : ã©ã®ã‚ˆã†ãªäººãŒã™ã‚‹è³ªå•ã‹
    information_category: str  # è¿½åŠ : æƒ…å ±ã®ã‚«ãƒ†ã‚´ãƒª
    related_keywords: List[str] # è¿½åŠ : é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    # è©•ä¾¡ãƒ»æ”¹å–„æƒ…å ±
    evaluation_score: Optional[int] = None  # æœ€çµ‚è©•ä¾¡ã‚¹ã‚³ã‚¢ (0-100)
    evaluation_rating: Optional[EvaluationScore] = None  # æœ€çµ‚è©•ä¾¡ãƒ¬ãƒ™ãƒ«
    improvement_iterations: Optional[int] = None  # æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«å®Ÿè¡Œå›æ•°

# --- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ1: Q&Aç”Ÿæˆå°‚ç”¨ ---
async def generate_basic_qa(
    source_identifier: str, # URLã‚„ãƒ•ã‚¡ã‚¤ãƒ«åãªã©ã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å‡ºå…¸
    text_content: str,
    existing_qa_for_source_display: List[str],
    model_name: str,
    attempt_number: int  # ä½•å›ç›®ã®è©¦è¡Œã‹ã‚’æ˜ç¤º
) -> Optional[BasicQAPair]:
    """
    åŸºæœ¬çš„ãªQ&Aãƒšã‚¢ã®ã¿ã‚’ç”Ÿæˆï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰
    """
    if not existing_qa_for_source_display:
        existing_qa_instructions_segment = "There are currently no existing Q&A pairs for this source."
    else:
        existing_qa_str = "\\n".join(existing_qa_for_source_display)
        existing_qa_instructions_segment = (
            f"The following Q&A pairs already exist for this source ({source_identifier}):\\n"
            f"Please generate a NEW Q&A pair that covers different aspects or provides different perspectives.\\n"
            f"---Existing Q&A Start---\\n"
            f"{existing_qa_str}\\n"
            f"---Existing Q&A End---"
        )

    # å€‹åˆ¥ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šã‚’å–å¾—
    config = agent_config.get_agent_config("qa_generation")
    
    qa_generation_agent = Agent(
        name="QA Generation Specialist",
        instructions=(
            "You are a specialized Q&A generation assistant focused solely on creating high-quality question-answer pairs.\\n"
            f"1. Analyze the provided text content from: {source_identifier} (likely a life insurance company's webpage).\\n"
            f"2. Text content: \\\\n---TEXT CONTENT BEGIN---\\\\n{text_content}\\\\n---TEXT CONTENT END---\\\\n"
            f"3. {existing_qa_instructions_segment}\\\\n"
            f"4. Generate ONE high-quality question-answer pair. Focus on:\\n"
            "   - Creating a natural, specific question someone would actually ask\\n"
            "   - If the answer varies based on conditions (age, gender, health status, contract details, timing, etc.), make the question specify those conditions clearly\\n"
            "   - If the answer differs by insurance product, include the specific product name in the question\\n"
            "   - For example: instead of 'ä¿é™ºé‡‘ã¯ã„ãã‚‰ã‚‚ã‚‰ãˆã¾ã™ã‹ï¼Ÿ' ask '30æ­³ç”·æ€§ãŒã¡ã‚ƒã‚“ã¨å¿œãˆã‚‹åŒ»ç™‚ä¿é™ºEVERã«åŠ å…¥ã—ãŸå ´åˆã€å…¥é™¢çµ¦ä»˜é‡‘ã¯ã„ãã‚‰ã‚‚ã‚‰ãˆã¾ã™ã‹ï¼Ÿ'\\n"
            "   - Another example: instead of 'ä¿é™ºæ–™ã®æ”¯æ‰•ã„æ–¹æ³•ã¯ï¼Ÿ' ask 'ã‚¢ãƒ•ãƒ©ãƒƒã‚¯ã®ãŒã‚“ä¿é™ºãƒ•ã‚©ãƒ«ãƒ†ã®ä¿é™ºæ–™æ”¯æ‰•ã„æ–¹æ³•ã«ã¯ã©ã®ã‚ˆã†ãªé¸æŠè‚¢ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ'\\n"
            "   - Providing a comprehensive, self-contained answer that addresses the specific conditions and products mentioned in the question\\n"
            "   - Avoiding generic or overly broad questions that could have multiple different answers\\n"
            "   - Including relevant details and context\\n"
            f"5. This is attempt #{attempt_number}, so try to find a unique angle or aspect not covered before.\\n"
            "6. The question and answer MUST be in Japanese.\\n"
            "7. The answer should be self-contained and directly address the question. Avoid answers that primarily redirect the user elsewhere.\\n"
            "8. Return exactly ONE BasicQAPair object with question, answer, and source_url fields only.\\n"
            f"9. The source_url must be exactly: '{source_identifier}'"
        ),
        output_type=BasicQAPair,
        model=config["model"],
    )

    try:
        result = await Runner.run(qa_generation_agent, input=f"Generate one high-quality Q&A for content from {source_identifier}")
        
        if result.final_output:
            qa = result.final_output
            # source_urlã®ä¿®æ­£
            if qa.source_url != source_identifier:
                qa_dict = qa.model_dump()
                qa_dict["source_url"] = source_identifier
                return BasicQAPair(**qa_dict)
            return qa
    except Exception as e:
        print(f"    âŒ Q&Aç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
    
    return None

# --- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ2: ãƒšãƒ«ã‚½ãƒŠåˆ†æå°‚ç”¨ ---
async def generate_persona(
    basic_qa: BasicQAPair,
    source_identifier: str,
    text_content: str,
    model_name: str
) -> Optional[PersonaResult]:
    """
    Q&Aãƒšãƒ«ã‚½ãƒŠåˆ†æå°‚ç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
    """
    # å€‹åˆ¥ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šã‚’å–å¾—
    config = agent_config.get_agent_config("persona_analysis")
    
    persona_agent = Agent(
        name="Persona Analysis Specialist",
        instructions=(
            "You are a specialized persona analysis assistant focused on identifying who would ask specific questions.\\n"
            f"1. Analyze the provided Q&A pair and its source context from: {source_identifier}\\n"
            f"2. Source context: \\n---SOURCE CONTENT---\\n{text_content[:1000]}...\\n---END SOURCE CONTENT---\\n"
            f"3. Q&A pair to analyze:\\n"
            f"   Question: {basic_qa.question}\\n"
            f"   Answer: {basic_qa.answer}\\n"
            "4. Determine the questioner_persona - who would likely ask this specific question?\\n"
            "5. Consider life insurance website visitors and their motivations:\\n"
            "   - 'å¥‘ç´„æ¤œè¨ä¸­ã®é¡§å®¢': Someone considering purchasing insurance\\n"
            "   - 'æ—¢å¥‘ç´„è€…': Existing policyholders with questions about their coverage\\n"
            "   - 'ä¿é™ºé‡‘å—å–äºº': Beneficiaries or claimants\\n"
            "   - 'å°±è·æ´»å‹•ä¸­ã®å­¦ç”Ÿ': Job-seeking students interested in company benefits\\n"
            "   - 'ä¸€èˆ¬çš„ãªæƒ…å ±åé›†è€…': General information seekers\\n"
            "   - 'ä¿é™ºæ–™ã‚’æ¤œè¨ä¸­ã®é¡§å®¢': Customers comparing premium costs\\n"
            "   - 'å¥åº·ã«é–¢å¿ƒãŒã‚ã‚‹äºº': Health-conscious individuals\\n"
            "   - 'ä»‹è­·ã«é–¢å¿ƒãŒã‚ã‚‹äºº': People interested in long-term care\\n"
            "6. Choose the most appropriate persona based on the question's content and intent.\\n"
            "7. The questioner_persona must be in Japanese.\\n"
            "8. Return exactly ONE PersonaResult object with questioner_persona field."
        ),
        output_type=PersonaResult,
        model=config["model"],
    )

    try:
        result = await Runner.run(persona_agent, input=f"Analyze persona for Q&A: {basic_qa.question}")
        return result.final_output if result.final_output else None
    except Exception as e:
        print(f"    âš ï¸ ãƒšãƒ«ã‚½ãƒŠåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        return None

# --- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ3: ã‚«ãƒ†ã‚´ãƒªåˆ†é¡å°‚ç”¨ ---
async def generate_category(
    basic_qa: BasicQAPair,
    source_identifier: str,
    text_content: str,
    model_name: str
) -> Optional[CategoryResult]:
    """
    Q&Aã‚«ãƒ†ã‚´ãƒªåˆ†é¡å°‚ç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
    """
    # å€‹åˆ¥ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šã‚’å–å¾—
    config = agent_config.get_agent_config("category_analysis")
    
    category_agent = Agent(
        name="Category Classification Specialist",
        instructions=(
            "You are a specialized category classification assistant focused on categorizing insurance-related Q&A pairs.\\n"
            f"1. Analyze the provided Q&A pair and its source context from: {source_identifier}\\n"
            f"2. Source context: \\n---SOURCE CONTENT---\\n{text_content[:1000]}...\\n---END SOURCE CONTENT---\\n"
            f"3. Q&A pair to analyze:\\n"
            f"   Question: {basic_qa.question}\\n"
            f"   Answer: {basic_qa.answer}\\n"
            "4. Determine the information_category - what type of information does this Q&A provide?\\n"
            "5. Choose from these standard insurance information categories:\\n"
            "   - 'å¥‘ç´„æ‰‹ç¶šã': Contract procedures, applications, policy changes\\n"
            "   - 'ä¿éšœå†…å®¹': Coverage details, benefits, policy features\\n"
            "   - 'ä¿é™ºé‡‘è«‹æ±‚': Claims procedures, benefit payments\\n"
            "   - 'å•†å“æ¯”è¼ƒ': Product comparisons, plan differences\\n"
            "   - 'ç¨é‡‘ãƒ»æ§é™¤': Tax implications, deductions\\n"
            "   - 'å¥åº·å¢—é€²ã‚µãƒ¼ãƒ“ã‚¹': Wellness services, health programs\\n"
            "   - 'ä¼šç¤¾æƒ…å ±': Company information, corporate data\\n"
            "   - 'ä¿é™ºæ–™ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³': Premium calculations, cost estimates\\n"
            "   - 'ç›¸è«‡æ–¹æ³•': Consultation methods, contact information\\n"
            "6. Select the most appropriate single category based on the primary focus of the Q&A.\\n"
            "7. The information_category must be in Japanese.\\n"
            "8. Return exactly ONE CategoryResult object with information_category field."
        ),
        output_type=CategoryResult,
        model=config["model"],
    )

    try:
        result = await Runner.run(category_agent, input=f"Classify category for Q&A: {basic_qa.question}")
        return result.final_output if result.final_output else None
    except Exception as e:
        print(f"    âš ï¸ ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# --- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ4: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºå°‚ç”¨ ---
async def generate_keywords(
    basic_qa: BasicQAPair,
    source_identifier: str,
    text_content: str,
    model_name: str
) -> Optional[KeywordsResult]:
    """
    Q&Aã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºå°‚ç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
    """
    # å€‹åˆ¥ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šã‚’å–å¾—
    config = agent_config.get_agent_config("keyword_extraction")
    
    keywords_agent = Agent(
        name="Keywords Extraction Specialist",
        instructions=(
            "You are a specialized keywords extraction assistant focused on identifying relevant search terms for insurance Q&A pairs.\\n"
            f"1. Analyze the provided Q&A pair and its source context from: {source_identifier}\\n"
            f"2. Source context: \\n---SOURCE CONTENT---\\n{text_content[:1000]}...\\n---END SOURCE CONTENT---\\n"
            f"3. Q&A pair to analyze:\\n"
            f"   Question: {basic_qa.question}\\n"
            f"   Answer: {basic_qa.answer}\\n"
            "4. Extract 3-5 related_keywords that represent the core topics and concepts in this Q&A.\\n"
            "5. Keywords should be:\\n"
            "   - Relevant to the insurance industry\\n"
            "   - Specific to the content of this Q&A\\n"
            "   - Useful for search and categorization\\n"
            "   - Include product names, procedures, or specific terms mentioned\\n"
            "   - Mix of general and specific terms\\n"
            "6. Example keywords for different topics:\\n"
            "   - For medical insurance: ['åŒ»ç™‚ä¿é™º', 'å…¥é™¢çµ¦ä»˜é‡‘', 'é€šé™¢', 'å¥åº·è¨ºæ–­']\\n"
            "   - For cancer insurance: ['ãŒã‚“ä¿é™º', 'è¨ºæ–­çµ¦ä»˜é‡‘', 'æ²»ç™‚è²»', 'å…ˆé€²åŒ»ç™‚']\\n"
            "   - For claims: ['ä¿é™ºé‡‘è«‹æ±‚', 'çµ¦ä»˜é‡‘', 'å¿…è¦æ›¸é¡', 'æ‰‹ç¶šã']\\n"
            "7. All keywords must be in Japanese.\\n"
            "8. Return exactly ONE KeywordsResult object with related_keywords list (3-5 items)."
        ),
        output_type=KeywordsResult,
        model=config["model"],
    )

    try:
        result = await Runner.run(keywords_agent, input=f"Extract keywords for Q&A: {basic_qa.question}")
        return result.final_output if result.final_output else None
    except Exception as e:
        print(f"    âš ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        return None

# --- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ5: Q&Aè©•ä¾¡å°‚ç”¨ ---
async def evaluate_qa_quality(
    basic_qa: BasicQAPair,
    source_identifier: str,
    text_content: str,
    model_name: str
) -> Optional[QAEvaluation]:
    """
    ç”Ÿæˆã•ã‚ŒãŸQ&Aã®å“è³ªã‚’è©•ä¾¡ã™ã‚‹å°‚ç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
    """
    # å€‹åˆ¥ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šã‚’å–å¾—
    config = agent_config.get_agent_config("qa_evaluation")
    
    evaluation_agent = Agent(
        name="QA Quality Evaluator",
        instructions=(
            "You are a specialized Q&A quality evaluation assistant focused on assessing insurance-related Q&A pairs.\\n"
            f"1. Analyze the provided Q&A pair and its source context from: {source_identifier}\\n"
            f"2. Source text content: \\n---SOURCE CONTENT BEGIN---\\n{text_content}\\n---SOURCE CONTENT END---\\n"
            f"3. Q&A pair to evaluate:\\n"
            f"   Question: {basic_qa.question}\\n"
            f"   Answer: {basic_qa.answer}\\n"
            "4. Evaluate based on these key criteria:\\n"
            "\\n"
            "**A. Source Coverage (0-100 points):**\\n"
            "   - Does the answer information exist in the source content?\\n"
            "   - Is the answer based on factual information from the source?\\n"
            "   - Are there any claims in the answer not supported by the source?\\n"
            "   - 100: Answer fully supported by source content\\n"
            "   - 80-99: Answer mostly supported, minor gaps\\n"
            "   - 60-79: Answer partially supported, some assumptions\\n"
            "   - 40-59: Answer weakly supported, significant gaps\\n"
            "   - 0-39: Answer not supported by source content\\n"
            "\\n"
            "**B. Question Specificity (0-100 points):**\\n"
            "   - Does the question include sufficient background information?\\n"
            "   - Are conditions clearly specified when answers vary by conditions?\\n"
            "   - Examples of good specificity:\\n"
            "     âœ… '30æ­³ç”·æ€§ãŒã¡ã‚ƒã‚“ã¨å¿œãˆã‚‹åŒ»ç™‚ä¿é™ºEVERã«åŠ å…¥ã—ãŸå ´åˆã€å…¥é™¢çµ¦ä»˜é‡‘ã¯ã„ãã‚‰ã‚‚ã‚‰ãˆã¾ã™ã‹ï¼Ÿ'\\n"
            "     âœ… 'ã‚¢ãƒ•ãƒ©ãƒƒã‚¯ã®ãŒã‚“ä¿é™ºãƒ•ã‚©ãƒ«ãƒ†ã®ä¿é™ºæ–™æ”¯æ‰•ã„æ–¹æ³•ã«ã¯ã©ã®ã‚ˆã†ãªé¸æŠè‚¢ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ'\\n"
            "   - Examples of poor specificity:\\n"
            "     âŒ 'ä¿é™ºé‡‘ã¯ã„ãã‚‰ã‚‚ã‚‰ãˆã¾ã™ã‹ï¼Ÿ'\\n"
            "     âŒ 'ä¿é™ºæ–™ã®æ”¯æ‰•ã„æ–¹æ³•ã¯ï¼Ÿ'\\n"
            "   - 100: Question is highly specific with all relevant conditions\\n"
            "   - 80-99: Question is mostly specific, minor conditions missing\\n"
            "   - 60-79: Question is moderately specific, some conditions unclear\\n"
            "   - 40-59: Question is somewhat vague, lacks important conditions\\n"
            "   - 0-39: Question is too generic, multiple interpretations possible\\n"
            "\\n"
            "**C. Condition Clarity (0-100 points):**\\n"
            "   - When the answer varies by age, gender, health status, product type, etc., are these conditions clearly stated in the question?\\n"
            "   - Does the question avoid ambiguity that could lead to different answers?\\n"
            "   - Are product names included when answers differ by insurance product?\\n"
            "   - 100: All relevant conditions clearly specified\\n"
            "   - 80-99: Most conditions specified, minor omissions\\n"
            "   - 60-79: Some conditions specified, notable gaps\\n"
            "   - 40-59: Few conditions specified, significant ambiguity\\n"
            "   - 0-39: Conditions not specified, highly ambiguous\\n"
            "\\n"
            "5. Calculate overall_score as weighted average: (source_coverage_score * 0.4 + question_specificity_score * 0.4 + condition_clarity_score * 0.2)\\n"
            "6. Determine overall_rating based on overall_score:\\n"
            "   - 90-100: excellent\\n"
            "   - 70-89: good\\n"
            "   - 50-69: fair\\n"
            "   - 0-49: poor\\n"
            "7. Provide specific feedback:\\n"
            "   - strengths: 2-3 positive aspects of the Q&A\\n"
            "   - improvement_areas: 2-3 areas that need improvement\\n"
            "   - specific_suggestions: 2-3 concrete suggestions for improvement\\n"
            "8. Set needs_improvement = true if overall_score < 80\\n"
            "9. Set improvement_priority: 'high' if score < 50, 'medium' if 50-79, 'low' if 80+\\n"
            "10. All text fields must be in Japanese.\\n"
            "11. Return exactly ONE QAEvaluation object with all required fields."
        ),
        output_type=QAEvaluation,
        model=config["model"],
    )

    try:
        result = await Runner.run(evaluation_agent, input=f"Evaluate Q&A quality: {basic_qa.question}")
        return result.final_output if result.final_output else None
    except Exception as e:
        print(f"    âš ï¸ Q&Aè©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# --- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ6: Q&Aæ”¹å–„å°‚ç”¨ ---
async def improve_qa_based_on_feedback(
    basic_qa: BasicQAPair,
    evaluation: QAEvaluation,
    source_identifier: str,
    text_content: str,
    model_name: str
) -> Optional[BasicQAPair]:
    """
    è©•ä¾¡ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«åŸºã¥ã„ã¦Q&Aã‚’æ”¹å–„ã™ã‚‹å°‚ç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
    """
    # å€‹åˆ¥ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šã‚’å–å¾—
    config = agent_config.get_agent_config("qa_improvement")
    
    improvement_agent = Agent(
        name="QA Improvement Specialist",
        instructions=(
            "You are a specialized Q&A improvement assistant focused on enhancing insurance-related Q&A pairs based on evaluation feedback.\\n"
            f"1. Source context: {source_identifier}\\n"
            f"2. Source text content: \\n---SOURCE CONTENT BEGIN---\\n{text_content}\\n---SOURCE CONTENT END---\\n"
            f"3. Original Q&A to improve:\\n"
            f"   Question: {basic_qa.question}\\n"
            f"   Answer: {basic_qa.answer}\\n"
            "4. Evaluation feedback received:\\n"
            f"   - Overall Score: {evaluation.overall_score}/100 ({evaluation.overall_rating})\\n"
            f"   - Source Coverage: {evaluation.source_coverage_score}/100\\n"
            f"   - Question Specificity: {evaluation.question_specificity_score}/100\\n"
            f"   - Condition Clarity: {evaluation.condition_clarity_score}/100\\n"
            f"   - Strengths: {', '.join(evaluation.strengths)}\\n"
            f"   - Improvement Areas: {', '.join(evaluation.improvement_areas)}\\n"
            f"   - Specific Suggestions: {', '.join(evaluation.specific_suggestions)}\\n"
            "\\n"
            "5. Based on the evaluation feedback, create an improved version of the Q&A pair:\\n"
            "\\n"
            "**For Question Improvement:**\\n"
            "   - Add specific conditions (age, gender, health status, product names) when missing\\n"
            "   - Make the question more specific and less ambiguous\\n"
            "   - Include relevant background information\\n"
            "   - Ensure the question clearly indicates the scope of the answer\\n"
            "\\n"
            "**For Answer Improvement:**\\n"
            "   - Ensure all information is directly supported by the source content\\n"
            "   - Remove any unsupported claims or assumptions\\n"
            "   - Add relevant details from the source when appropriate\\n"
            "   - Make the answer more comprehensive while staying factual\\n"
            "   - Address the specific conditions mentioned in the improved question\\n"
            "\\n"
            "6. Focus on addressing the specific improvement areas identified in the evaluation\\n"
            "7. The improved question and answer MUST be in Japanese\\n"
            "8. Ensure the improved Q&A addresses all the concerns raised in the evaluation\\n"
            f"9. The source_url must be exactly: '{source_identifier}'\\n"
            "10. Return exactly ONE BasicQAPair object with the improved question and answer"
        ),
        output_type=BasicQAPair,
        model=config["model"],
    )

    try:
        result = await Runner.run(improvement_agent, input=f"Improve Q&A based on feedback: {basic_qa.question}")
        
        if result.final_output:
            improved_qa = result.final_output
            # source_urlã®ä¿®æ­£
            if improved_qa.source_url != source_identifier:
                qa_dict = improved_qa.model_dump()
                qa_dict["source_url"] = source_identifier
                return BasicQAPair(**qa_dict)
            return improved_qa
    except Exception as e:
        print(f"    âš ï¸ Q&Aæ”¹å–„ã‚¨ãƒ©ãƒ¼: {e}")
    
    return None

# --- çµ±åˆé–¢æ•°: è©•ä¾¡ãƒ»æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«ä»˜ãQ&Aç”Ÿæˆ ---
async def generate_complete_qa_with_evaluation(
    source_identifier: str,
    text_content: str,
    existing_qa_for_source_display: List[str],
    model_name: str,
    attempt_number: int,
    max_improvement_iterations: int = 2
) -> Optional[QAPair]:
    """
    è©•ä¾¡ãƒ»æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«ä»˜ãã§å®Œå…¨ãªQ&Aãƒšã‚¢ã‚’ç”Ÿæˆ
    """
    # Step 1: åŸºæœ¬Q&Aç”Ÿæˆ
    basic_qa = await generate_basic_qa(
        source_identifier,
        text_content,
        existing_qa_for_source_display,
        model_name,
        attempt_number
    )
    
    if not basic_qa:
        print(f"    âŒ åŸºæœ¬Q&Aç”Ÿæˆå¤±æ•—")
        return None
    
    print(f"    âœ… åŸºæœ¬Q&Aç”ŸæˆæˆåŠŸ: {basic_qa.question[:50]}...")
    
    # Step 2: Q&Aå“è³ªè©•ä¾¡
    print(f"    ğŸ” Q&Aå“è³ªè©•ä¾¡ä¸­...")
    evaluation = await evaluate_qa_quality(
        basic_qa,
        source_identifier,
        text_content,
        model_name
    )
    
    if not evaluation:
        print(f"    âš ï¸ è©•ä¾¡å¤±æ•—ã€åŸºæœ¬Q&Aã§ç¶šè¡Œ")
        current_qa = basic_qa
        evaluation_score = None
        evaluation_rating = None
        improvement_iterations = 0
    else:
        print(f"    ğŸ“Š è©•ä¾¡å®Œäº†: {evaluation.overall_score}/100 ({evaluation.overall_rating})")
        print(f"    ğŸ“ˆ å†…è¨³: ã‚½ãƒ¼ã‚¹æ•´åˆæ€§={evaluation.source_coverage_score}, è³ªå•ç‰¹å®šæ€§={evaluation.question_specificity_score}, æ¡ä»¶æ˜ç¢ºæ€§={evaluation.condition_clarity_score}")
        
        current_qa = basic_qa
        evaluation_score = evaluation.overall_score
        evaluation_rating = evaluation.overall_rating
        improvement_iterations = 0
        
        # Step 3: æ”¹å–„ãŒå¿…è¦ãªå ´åˆã¯æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«å®Ÿè¡Œ
        if evaluation.needs_improvement and evaluation.improvement_priority in ["high", "medium"]:
            print(f"    ğŸ”§ æ”¹å–„å¿…è¦ (å„ªå…ˆåº¦: {evaluation.improvement_priority})")
            
            for iteration in range(max_improvement_iterations):
                print(f"    ğŸ”„ æ”¹å–„è©¦è¡Œ {iteration + 1}/{max_improvement_iterations}")
                
                improved_qa = await improve_qa_based_on_feedback(
                    current_qa,
                    evaluation,
                    source_identifier,
                    text_content,
                    model_name
                )
                
                if improved_qa:
                    print(f"    âœ… Q&Aæ”¹å–„æˆåŠŸ")
                    print(f"    ğŸ“ æ”¹å–„å‰: {current_qa.question[:40]}...")
                    print(f"    ğŸ“ æ”¹å–„å¾Œ: {improved_qa.question[:40]}...")
                    
                    # æ”¹å–„ç‰ˆã‚’å†è©•ä¾¡
                    re_evaluation = await evaluate_qa_quality(
                        improved_qa,
                        source_identifier,
                        text_content,
                        model_name
                    )
                    
                    if re_evaluation and re_evaluation.overall_score > evaluation.overall_score:
                        print(f"    ğŸ“ˆ å“è³ªå‘ä¸Š: {evaluation.overall_score} â†’ {re_evaluation.overall_score}")
                        current_qa = improved_qa
                        evaluation = re_evaluation
                        evaluation_score = re_evaluation.overall_score
                        evaluation_rating = re_evaluation.overall_rating
                        improvement_iterations = iteration + 1
                        
                        # ååˆ†ãªå“è³ªã«é”ã—ãŸå ´åˆã¯æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«çµ‚äº†
                        if re_evaluation.overall_score >= 80:
                            print(f"    ğŸ¯ ç›®æ¨™å“è³ªé”æˆ ({re_evaluation.overall_score}/100)")
                            break
                    else:
                        print(f"    ğŸ“Š æ”¹å–„åŠ¹æœé™å®šçš„ã€å…ƒã®Q&Aã‚’æ¡ç”¨")
                        break
                else:
                    print(f"    âŒ Q&Aæ”¹å–„å¤±æ•—")
                    break
                
                await asyncio.sleep(1)  # æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«é–“ã®å¾…æ©Ÿ
        else:
            print(f"    âœ… å“è³ªè‰¯å¥½ã€æ”¹å–„ä¸è¦")
    
    # Step 4-6: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆæ—¢å­˜ã®3ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä¸¦åˆ—å®Ÿè¡Œï¼‰
    print(f"    ğŸ” ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åˆ†æä¸­...")
    
    persona_task = generate_persona(current_qa, source_identifier, text_content, model_name)
    category_task = generate_category(current_qa, source_identifier, text_content, model_name)  
    keywords_task = generate_keywords(current_qa, source_identifier, text_content, model_name)
    
    persona_result, category_result, keywords_result = await asyncio.gather(
        persona_task, category_task, keywords_task, return_exceptions=True
    )
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿çµæœã®å‡¦ç†
    persona = "ä¸€èˆ¬çš„ãªæƒ…å ±åé›†è€…"
    if isinstance(persona_result, PersonaResult):
        persona = persona_result.questioner_persona
        print(f"    âœ… ãƒšãƒ«ã‚½ãƒŠåˆ†ææˆåŠŸ: {persona}")
    else:
        print(f"    âš ï¸ ãƒšãƒ«ã‚½ãƒŠåˆ†æå¤±æ•—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ä½¿ç”¨: {persona}")
    
    category = "ãã®ä»–"
    if isinstance(category_result, CategoryResult):
        category = category_result.information_category
        print(f"    âœ… ã‚«ãƒ†ã‚´ãƒªåˆ†é¡æˆåŠŸ: {category}")
    else:
        print(f"    âš ï¸ ã‚«ãƒ†ã‚´ãƒªåˆ†é¡å¤±æ•—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ä½¿ç”¨: {category}")
    
    keywords = ["ä¿é™º", "æƒ…å ±"]
    if isinstance(keywords_result, KeywordsResult):
        keywords = keywords_result.related_keywords
        print(f"    âœ… ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºæˆåŠŸ: {keywords}")
    else:
        print(f"    âš ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºå¤±æ•—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ä½¿ç”¨: {keywords}")
    
    # Step 7: å®Œå…¨ãªQ&Aãƒšã‚¢ã‚’æ§‹ç¯‰
    complete_qa = QAPair(
        question=current_qa.question,
        answer=current_qa.answer,
        source_url=current_qa.source_url,
        questioner_persona=persona,
        information_category=category,
        related_keywords=keywords,
        evaluation_score=evaluation_score,
        evaluation_rating=evaluation_rating,
        improvement_iterations=improvement_iterations
    )
    
    return complete_qa

# --- çµ±åˆé–¢æ•°: åŸºæœ¬Q&Aç”Ÿæˆ + 3ã¤ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆè©•ä¾¡ãªã—ï¼‰ ---
async def generate_complete_qa_without_evaluation(
    source_identifier: str,
    text_content: str,
    existing_qa_for_source_display: List[str],
    model_name: str,
    attempt_number: int
) -> Optional[QAPair]:
    """
    å®Œå…¨ãªQ&Aãƒšã‚¢ï¼ˆåŸºæœ¬Q&A + 3ã¤ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰ã‚’ç”Ÿæˆï¼ˆè©•ä¾¡ãƒ»æ”¹å–„ãªã—ï¼‰
    """
    # Step 1: åŸºæœ¬Q&Aç”Ÿæˆ
    basic_qa = await generate_basic_qa(
        source_identifier,
        text_content,
        existing_qa_for_source_display,
        model_name,
        attempt_number
    )
    
    if not basic_qa:
        print(f"    âŒ åŸºæœ¬Q&Aç”Ÿæˆå¤±æ•—")
        return None
    
    print(f"    âœ… åŸºæœ¬Q&Aç”ŸæˆæˆåŠŸ: {basic_qa.question[:50]}...")
    
    # Step 2-4: 3ã¤ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä¸¦åˆ—å®Ÿè¡Œ
    print(f"    ğŸ” ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åˆ†æä¸­...")
    
    # ä¸¦åˆ—ã§ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    persona_task = generate_persona(basic_qa, source_identifier, text_content, model_name)
    category_task = generate_category(basic_qa, source_identifier, text_content, model_name)
    keywords_task = generate_keywords(basic_qa, source_identifier, text_content, model_name)
    
    # ä¸¦åˆ—å®Ÿè¡Œ
    persona_result, category_result, keywords_result = await asyncio.gather(
        persona_task, category_task, keywords_task, return_exceptions=True
    )
    
    # çµæœã®æ¤œè¨¼ã¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤è¨­å®š
    persona = "ä¸€èˆ¬çš„ãªæƒ…å ±åé›†è€…"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    if isinstance(persona_result, PersonaResult):
        persona = persona_result.questioner_persona
        print(f"    âœ… ãƒšãƒ«ã‚½ãƒŠåˆ†ææˆåŠŸ: {persona}")
    else:
        print(f"    âš ï¸ ãƒšãƒ«ã‚½ãƒŠåˆ†æå¤±æ•—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ä½¿ç”¨: {persona}")
    
    category = "ãã®ä»–"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    if isinstance(category_result, CategoryResult):
        category = category_result.information_category
        print(f"    âœ… ã‚«ãƒ†ã‚´ãƒªåˆ†é¡æˆåŠŸ: {category}")
    else:
        print(f"    âš ï¸ ã‚«ãƒ†ã‚´ãƒªåˆ†é¡å¤±æ•—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ä½¿ç”¨: {category}")
    
    keywords = ["ä¿é™º", "æƒ…å ±"]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    if isinstance(keywords_result, KeywordsResult):
        keywords = keywords_result.related_keywords
        print(f"    âœ… ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºæˆåŠŸ: {keywords}")
    else:
        print(f"    âš ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºå¤±æ•—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ä½¿ç”¨: {keywords}")
    
    # Step 5: å®Œå…¨ãªQ&Aãƒšã‚¢ã‚’æ§‹ç¯‰ï¼ˆè©•ä¾¡ãªã—ãƒ¢ãƒ¼ãƒ‰ï¼‰
    complete_qa = QAPair(
        question=basic_qa.question,
        answer=basic_qa.answer,
        source_url=basic_qa.source_url,
        questioner_persona=persona,
        information_category=category,
        related_keywords=keywords,
        evaluation_score=None,  # è©•ä¾¡ãªã—ãƒ¢ãƒ¼ãƒ‰
        evaluation_rating=None,
        improvement_iterations=0  # æ”¹å–„å®Ÿè¡Œãªã—
    )
    
    return complete_qa

# --- ä¸¦åˆ—å‡¦ç†å¯¾å¿œ: ãƒ•ã‚¡ã‚¤ãƒ«I/O ãƒ­ãƒƒã‚¯ç®¡ç† ---
import threading
import time
from datetime import datetime

# ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ç”¨ãƒ­ãƒƒã‚¯
file_lock = threading.Lock()

def collect_existing_qa_for_source(source_identifier: str, outfile: str) -> List[str]:
    """
    æŒ‡å®šã•ã‚ŒãŸã‚½ãƒ¼ã‚¹IDã«é–¢ã™ã‚‹æ—¢å­˜Q&Aã‚’åé›†
    """
    existing_qa_display = []
    if os.path.exists(outfile):
        try:
            with file_lock:  # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æ™‚ã‚‚ãƒ­ãƒƒã‚¯
                with jsonlines.open(outfile, "r") as reader:
                    for qa_obj_dict in reader:
                        if qa_obj_dict.get("source_url") == source_identifier:
                            q = qa_obj_dict.get("question")
                            a = qa_obj_dict.get("answer")
                            if q and a:
                                existing_qa_display.append(f"- Q: {q}\\n  A: {a}")
        except Exception as e:
            print(f"è­¦å‘Š: æ—¢å­˜Q&Aåé›†ä¸­ã«ã‚¨ãƒ©ãƒ¼ ({source_identifier}): {e}")
    return existing_qa_display

def save_qa_to_file(qa: QAPair, outfile: str) -> bool:
    """
    Q&Aã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«å®‰å…¨ã«ä¿å­˜
    """
    try:
        with file_lock:  # ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿æ™‚ã®ãƒ­ãƒƒã‚¯
            with jsonlines.open(outfile, "a") as writer:
                writer.write(qa.model_dump())
        return True
    except Exception as e:
        print(f"Q&Aä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return False

async def process_single_entry(
    entry_data: Tuple[int, Dict[str, Any]],
    outfile: str,
    model_name: str,
    source_id_field: str,
    content_field: str,
    max_q_per_entry: int,
    global_existing_qa_set: Set[Tuple[str, str]],
    enable_evaluation: bool = True,
    max_improvement_iterations: int = 2
) -> int:
    """
    å˜ä¸€ã‚¨ãƒ³ãƒˆãƒªã®å‡¦ç†ï¼ˆè©•ä¾¡ãƒ»æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«ä»˜ãï¼‰
    """
    i, entry = entry_data
    
    source_identifier = entry.get(source_id_field)
    text_content = entry.get(content_field)
    
    if not source_identifier:
        print(f"âš ï¸ ã‚¨ãƒ³ãƒˆãƒª {i+1}: '{source_id_field}' ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ç©ºã§ã™ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return 0
    if not text_content:
        print(f"âš ï¸ ã‚¨ãƒ³ãƒˆãƒª {i+1}: '{content_field}' ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ç©ºã§ã™ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return 0

    print(f"ğŸ”„ ã‚¨ãƒ³ãƒˆãƒª {i+1} ã‚’å‡¦ç†ä¸­: {source_identifier}")

    # ã“ã®ã‚½ãƒ¼ã‚¹ã®æ—¢å­˜Q&Aã‚’åé›†
    existing_qa_for_current_source_display = collect_existing_qa_for_source(source_identifier, outfile)
    
    # ã‚¨ãƒ³ãƒˆãƒªå†…ã§ã®Q&Aç”Ÿæˆã¯é€æ¬¡å®Ÿè¡Œï¼ˆå“è³ªé‡è¦–ï¼‰
    current_entry_added_count = 0
    for attempt in range(max_q_per_entry):
        print(f"  ğŸ“ ã‚¨ãƒ³ãƒˆãƒª {i+1}, è©¦è¡Œ {attempt + 1}/{max_q_per_entry}")
        
        if enable_evaluation:
            # è©•ä¾¡ãƒ»æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«ä»˜ãã§Q&Aç”Ÿæˆ
            complete_qa = await generate_complete_qa_with_evaluation(
                source_identifier,
                text_content,
                existing_qa_for_current_source_display,
                model_name,
                attempt + 1,
                max_improvement_iterations
            )
        else:
            # å¾“æ¥ã®4æ®µéšå‡¦ç†ï¼ˆè©•ä¾¡ãªã—ï¼‰
            complete_qa = await generate_complete_qa_without_evaluation(
                source_identifier,
                text_content,
                existing_qa_for_current_source_display,
                model_name,
                attempt + 1
            )
        
        if complete_qa:
            current_qa_tuple = (complete_qa.question, complete_qa.answer)
            
            # ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ï¼‰
            with file_lock:
                is_duplicate = current_qa_tuple in global_existing_qa_set
                if not is_duplicate:
                    global_existing_qa_set.add(current_qa_tuple)
            
            if not is_duplicate:
                # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                if save_qa_to_file(complete_qa, outfile):
                    # æ¬¡ã®è©¦è¡Œã§ä½¿ç”¨ã™ã‚‹ãŸã‚ã€ã“ã®ã‚¨ãƒ³ãƒˆãƒªã®æ—¢å­˜ãƒªã‚¹ãƒˆã«è¿½åŠ 
                    existing_qa_for_current_source_display.append(
                        f"- Q: {complete_qa.question}\\n  A: {complete_qa.answer}"
                    )
                    current_entry_added_count += 1
                    print(f"    âœ… å®Œå…¨Q&Aç”ŸæˆæˆåŠŸ")
                else:
                    print(f"    âŒ Q&Aä¿å­˜å¤±æ•—")
            else:
                print(f"    âš ï¸ é‡è¤‡ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {complete_qa.question[:50]}...")
        else:
            print(f"    âŒ Q&Aç”Ÿæˆå¤±æ•—")
        
        # è©•ä¾¡ãƒ»æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«ãŒã‚ã‚‹å ´åˆã¯å¾…æ©Ÿæ™‚é–“ã‚’å»¶é•·
        wait_time = 5 if enable_evaluation else 3
        await asyncio.sleep(wait_time)
    
    if current_entry_added_count > 0:
        print(f"âœ¨ ã‚¨ãƒ³ãƒˆãƒª {i+1}: {current_entry_added_count} ä»¶ã‚’æ–°ãŸã«ç”Ÿæˆ")
    else:
        print(f"â„¹ï¸ ã‚¨ãƒ³ãƒˆãƒª {i+1}: æ–°ã—ã„Q&Aã¯ç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
    
    # ã‚¨ãƒ³ãƒˆãƒªé–“ã®å¾…æ©Ÿ
    await asyncio.sleep(0.5)
    return current_entry_added_count

# --- ã‚¨ãƒ³ãƒˆãƒªãƒ¬ãƒ™ãƒ«ä¸¦åˆ—å‡¦ç†ã®ãƒ¡ã‚¤ãƒ³é–¢æ•° ---
async def process_jsonl_parallel_entries(
    input_jsonl_path: str,
    outfile: str,
    model_name: str,
    source_id_field: str,
    content_field: str,
    max_q_per_entry: int = 1,
    max_entries_to_process: int = -1,
    max_concurrent_entries: int = 1,  # è©•ä¾¡ãƒ»æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«ã®ãŸã‚1ã«å¤‰æ›´
    enable_evaluation: bool = True,
    max_improvement_iterations: int = 2
):
    """
    ã‚¨ãƒ³ãƒˆãƒªãƒ¬ãƒ™ãƒ«ä¸¦åˆ—å‡¦ç†ã§JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ï¼ˆè©•ä¾¡ãƒ»æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«ä»˜ãï¼‰
    """
    if not os.path.exists(input_jsonl_path):
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ« '{input_jsonl_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return

    # æ—¢å­˜Q&Aã®èª­ã¿è¾¼ã¿
    global_existing_qa_set: Set[Tuple[str, str]] = set()
    if os.path.exists(outfile):
        try:
            with jsonlines.open(outfile, "r") as reader:
                for qa_obj_dict in reader:
                    global_existing_qa_set.add((qa_obj_dict.get("question"), qa_obj_dict.get("answer")))
            print(f"ğŸ“‚ æ—¢å­˜ã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ« '{outfile}' ã‹ã‚‰ {len(global_existing_qa_set)} ä»¶ã®Q&Aã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
        except Exception as e:
            print(f"âš ï¸ è­¦å‘Š: æ—¢å­˜ã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ« '{outfile}' ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

    # ã‚¨ãƒ³ãƒˆãƒªã‚’èª­ã¿è¾¼ã¿
    entries = []
    with jsonlines.open(input_jsonl_path, "r") as reader:
        for i, entry in enumerate(reader):
            if max_entries_to_process != -1 and i >= max_entries_to_process:
                break
            entries.append((i, entry))

    processing_mode = "è©•ä¾¡ãƒ»æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«ä»˜ã" if enable_evaluation else "æ¨™æº–4æ®µéš"
    agent_count = "6å€‹ (Q&Aç”Ÿæˆ + è©•ä¾¡ + æ”¹å–„ + ãƒšãƒ«ã‚½ãƒŠ + ã‚«ãƒ†ã‚´ãƒª + ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰)" if enable_evaluation else "4å€‹ (Q&Aç”Ÿæˆ + ãƒšãƒ«ã‚½ãƒŠ + ã‚«ãƒ†ã‚´ãƒª + ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰)"
    
    print(f"\nğŸš€ Q&Aç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")
    print(f"=" * 60)
    print(f"ğŸ“‚ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {input_jsonl_path}")
    print(f"ğŸ’¾ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {outfile}")
    print(f"ğŸ”¢ å‡¦ç†ã‚¨ãƒ³ãƒˆãƒªæ•°: {len(entries)}")
    print(f"ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}")
    print(f"ğŸ“Š ã‚¨ãƒ³ãƒˆãƒªã‚ãŸã‚ŠQ&Aæ•°: {max_q_per_entry}")
    print(f"âš¡ æœ€å¤§ä¸¦åˆ—æ•°: {max_concurrent_entries}")
    print(f"ğŸ”§ å‡¦ç†ãƒ¢ãƒ¼ãƒ‰: {processing_mode}")
    print(f"ğŸ¤– ä½¿ç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ•°: {agent_count}")
    if enable_evaluation:
        print(f"ğŸ”„ æœ€å¤§æ”¹å–„è©¦è¡Œå›æ•°: {max_improvement_iterations}")
    print(f"=" * 60)
    
    start_time = time.time()

    # ä¸¦åˆ—å‡¦ç†ç”¨ã‚»ãƒãƒ•ã‚©
    semaphore = asyncio.Semaphore(max_concurrent_entries)
    
    async def process_entry_with_semaphore(entry_data):
        async with semaphore:
            return await process_single_entry(
                entry_data,
                outfile,
                model_name,
                source_id_field,
                content_field,
                max_q_per_entry,
                global_existing_qa_set,
                enable_evaluation,
                max_improvement_iterations
            )
    
    # ä¸¦åˆ—å®Ÿè¡Œ
    tasks = [process_entry_with_semaphore(entry_data) for entry_data in entries]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # çµæœé›†è¨ˆ
    total_newly_added = sum(r for r in results if isinstance(r, int))
    error_count = sum(1 for r in results if isinstance(r, Exception))
    
    end_time = time.time()
    processing_time = end_time - start_time
    
    print(f"\nğŸ“Š å‡¦ç†å®Œäº†ã‚µãƒãƒªãƒ¼")
    print(f"=" * 60)
    print(f"ğŸ‰ æ–°è¦Q&Aç”Ÿæˆæ•°: {total_newly_added} ä»¶")
    print(f"â±ï¸ å‡¦ç†æ™‚é–“: {processing_time:.2f} ç§’")
    print(f"âš¡ å¹³å‡å‡¦ç†é€Ÿåº¦: {len(entries) / processing_time:.2f} ã‚¨ãƒ³ãƒˆãƒª/ç§’")
    if error_count > 0:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿã‚¨ãƒ³ãƒˆãƒªæ•°: {error_count} ä»¶")
    print(f"ğŸ’¾ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {outfile}")
    print(f"ğŸ”§ å‡¦ç†ãƒ¢ãƒ¼ãƒ‰: {processing_mode}")
    print(f"=" * 60)

# --- ä¸‹ä½äº’æ›æ€§ã®ãŸã‚ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ ---
async def process_jsonl_single_qa_mode(
    input_jsonl_path: str,
    outfile: str,
    model_name: str,
    source_id_field: str,
    content_field: str,
    max_q_per_entry: int = 3,
    max_entries_to_process: int = -1,
):
    """
    ä¸‹ä½äº’æ›æ€§ã®ãŸã‚ã®é–¢æ•°ï¼ˆä¸¦åˆ—å‡¦ç†ç‰ˆã‚’å‘¼ã³å‡ºã—ï¼‰
    """
    await process_jsonl_parallel_entries(
        input_jsonl_path,
        outfile,
        model_name,
        source_id_field,
        content_field,
        max_q_per_entry,
        max_entries_to_process,
        max_concurrent_entries=1  # é€æ¬¡å‡¦ç†ãƒ¢ãƒ¼ãƒ‰
    )


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="6æ®µéšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡¦ç†ã§JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰Q&Aãƒšã‚¢ç”Ÿæˆï¼ˆè©•ä¾¡ãƒ»æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«ä»˜ãï¼‰")
    parser.add_argument("--input_jsonl", required=True, help="å…¥åŠ›JSONLãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹")
    parser.add_argument("--outfile", required=True, help="å‡ºåŠ›JSONLãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹")
    parser.add_argument("--model", default="gpt-4o-mini", help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šä¸Šæ›¸ãç”¨ï¼‰")
    parser.add_argument("--source_id_field", default="url", help="ã‚½ãƒ¼ã‚¹IDç”¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å")
    parser.add_argument("--content_field", default="response_body", help="ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å")
    parser.add_argument("--max_q_per_entry", type=int, default=1, help="ã‚¨ãƒ³ãƒˆãƒªã‚ãŸã‚Šæœ€å¤§Q&Aæ•°")
    parser.add_argument("--max_entries", type=int, default=-1, help="å‡¦ç†ã™ã‚‹ã‚¨ãƒ³ãƒˆãƒªæ•°ä¸Šé™ï¼ˆ-1ã§å…¨ã¦ï¼‰")
    parser.add_argument("--max_concurrent", type=int, default=1, help="ä¸¦åˆ—å®Ÿè¡Œæ•°")
    parser.add_argument("--disable_evaluation", action="store_true", help="è©•ä¾¡ãƒ»æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«ã‚’ç„¡åŠ¹åŒ–")
    parser.add_argument("--max_improvement_iterations", type=int, default=2, help="æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«æœ€å¤§å›æ•°")
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument("--quality_mode", choices=["standard", "balanced", "all_premium"], default="balanced", 
                        help="å“è³ªãƒ¢ãƒ¼ãƒ‰: standardï¼ˆå…¨ã¦gpt-4o-miniï¼‰, balancedï¼ˆé‡è¦ã‚¿ã‚¹ã‚¯gpt-4oï¼‰, all_premiumï¼ˆå…¨ã¦gpt-4oï¼‰")
    parser.add_argument("--qa_generation_model", help="Q&Aç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå°‚ç”¨ãƒ¢ãƒ‡ãƒ«")
    parser.add_argument("--evaluation_model", help="è©•ä¾¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå°‚ç”¨ãƒ¢ãƒ‡ãƒ«")
    parser.add_argument("--improvement_model", help="æ”¹å–„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå°‚ç”¨ãƒ¢ãƒ‡ãƒ«")
    parser.add_argument("--persona_model", help="ãƒšãƒ«ã‚½ãƒŠåˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå°‚ç”¨ãƒ¢ãƒ‡ãƒ«")
    parser.add_argument("--category_model", help="ã‚«ãƒ†ã‚´ãƒªåˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå°‚ç”¨ãƒ¢ãƒ‡ãƒ«")
    parser.add_argument("--keywords_model", help="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå°‚ç”¨ãƒ¢ãƒ‡ãƒ«")
    
    args = parser.parse_args()
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šã®é©ç”¨
    agent_config.set_quality_mode(args.quality_mode)
    
    # å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«è¨­å®šã®é©ç”¨
    if args.qa_generation_model:
        agent_config.set_agent_model("qa_generation", args.qa_generation_model)
    if args.evaluation_model:
        agent_config.set_agent_model("qa_evaluation", args.evaluation_model)
    if args.improvement_model:
        agent_config.set_agent_model("qa_improvement", args.improvement_model)
    if args.persona_model:
        agent_config.set_agent_model("persona_analysis", args.persona_model)
    if args.category_model:
        agent_config.set_agent_model("category_analysis", args.category_model)
    if args.keywords_model:
        agent_config.set_agent_model("keyword_extraction", args.keywords_model)
    
    # è¨­å®šè¡¨ç¤º
    print("ğŸš€ 6æ®µéšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡¦ç†é–‹å§‹")
    print(f"ğŸ“„ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {args.input_jsonl}")
    print(f"ğŸ“‹ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {args.outfile}")
    print(f"ğŸ¯ å“è³ªãƒ¢ãƒ¼ãƒ‰: {args.quality_mode}")
    print(f"ğŸ”„ è©•ä¾¡ãƒ»æ”¹å–„: {'æœ‰åŠ¹' if not args.disable_evaluation else 'ç„¡åŠ¹'}")
    agent_config.print_config()
    print()
    
    asyncio.run(process_jsonl_parallel_entries(
        args.input_jsonl,
        args.outfile,
        args.model,
        args.source_id_field,
        args.content_field,
        args.max_q_per_entry,
        args.max_entries,
        args.max_concurrent,
        not args.disable_evaluation,  # enable_evaluation
        args.max_improvement_iterations
    ))

"""
ğŸ”§ ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå€‹åˆ¥è¨­å®šã®ä½¿ç”¨ä¾‹ã€‘

# 1. å“è³ªãƒ¢ãƒ¼ãƒ‰è¨­å®š
--quality_mode standard     # å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆgpt-4o-miniï¼ˆä½ã‚³ã‚¹ãƒˆï¼‰
--quality_mode balanced     # é‡è¦ã‚¿ã‚¹ã‚¯ã®ã¿gpt-4oï¼ˆæ¨å¥¨ï¼‰
--quality_mode all_premium  # å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆgpt-4oï¼ˆæœ€é«˜å“è³ªï¼‰

# 2. å€‹åˆ¥ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®š
--qa_generation_model gpt-4o        # Q&Aç”Ÿæˆã®ã¿é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«
--evaluation_model gpt-4o-mini      # è©•ä¾¡ã¯åŠ¹ç‡é‡è¦–
--improvement_model gpt-4o          # æ”¹å–„ã¯é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«
--persona_model gpt-4o-mini         # ãƒšãƒ«ã‚½ãƒŠåˆ†æã¯åŠ¹ç‡é‡è¦–
--category_model gpt-4o-mini        # ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ã¯åŠ¹ç‡é‡è¦–
--keywords_model gpt-4o-mini        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã¯åŠ¹ç‡é‡è¦–

# 3. ã‚³ã‚¹ãƒˆæœ€é©åŒ–ã®ä¾‹ï¼ˆé‡è¦ãªå‡¦ç†ã®ã¿é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ï¼‰
python Create_QA_from_jsonl_alt_fixed.py \
    --input_jsonl data.jsonl \
    --outfile output.jsonl \
    --quality_mode standard \
    --qa_generation_model gpt-4o \
    --evaluation_model gpt-4o

# 4. æœ€é«˜å“è³ªè¨­å®šã®ä¾‹
python Create_QA_from_jsonl_alt_fixed.py \
    --input_jsonl data.jsonl \
    --outfile output.jsonl \
    --quality_mode all_premium

# 5. ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã®ä¾‹
python Create_QA_from_jsonl_alt_fixed.py \
    --input_jsonl data.jsonl \
    --outfile output.jsonl \
    --qa_generation_model gpt-4o \
    --improvement_model gpt-4o \
    --evaluation_model gpt-4o-mini \
    --persona_model gpt-4o-mini \
    --category_model gpt-4o-mini \
    --keywords_model gpt-4o-mini

ã“ã‚Œã«ã‚ˆã‚Šã€ä»¥ä¸‹ã®ã‚ˆã†ãªæŸ”è»Ÿãªé‹ç”¨ãŒå¯èƒ½ã§ã™ï¼š
âœ… ã‚³ã‚¹ãƒˆé‡è¦–: åˆ†é¡ç³»ã‚¿ã‚¹ã‚¯ã¯åŠ¹ç‡çš„ãªãƒ¢ãƒ‡ãƒ«ã€ç”Ÿæˆç³»ã¯é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«
âœ… å“è³ªé‡è¦–: å…¨ã¦ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§æœ€é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
âœ… ãƒãƒ©ãƒ³ã‚¹é‡è¦–: é‡è¦åº¦ã«å¿œã˜ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã„åˆ†ã‘
âœ… å®Ÿé¨“çš„é‹ç”¨: ç‰¹å®šã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã¿ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚¹ãƒˆ

è©•ä¾¡ãƒ»æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«ä»˜ã6æ®µéšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡¦ç†ã§JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰Q&Aãƒšã‚¢ç”Ÿæˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é«˜å“è³ªãªQ&Aãƒšã‚¢ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã«ã€
6ã¤ã®å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ï¼š

1. Q&Aç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: åŸºæœ¬çš„ãªè³ªå•-å›ç­”ãƒšã‚¢ã‚’ç”Ÿæˆ
2. Q&Aè©•ä¾¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: ç”Ÿæˆã•ã‚ŒãŸQ&Aã®å“è³ªã‚’è©•ä¾¡
3. Q&Aæ”¹å–„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: è©•ä¾¡ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«åŸºã¥ã„ã¦Q&Aã‚’æ”¹å–„
4. ãƒšãƒ«ã‚½ãƒŠåˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: è³ªå•è€…ã®ãƒšãƒ«ã‚½ãƒŠã‚’ç‰¹å®š
5. ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: æƒ…å ±ã‚«ãƒ†ã‚´ãƒªã‚’åˆ†é¡
6. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º

å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ç‰¹å®šã®å°‚é–€åˆ†é‡ã«é›†ä¸­ã—ã€é«˜å“è³ªãªçµæœã‚’æä¾›ã—ã¾ã™ã€‚
è©•ä¾¡ãƒ»æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«ã«ã‚ˆã‚Šã€è‡ªå‹•çš„ã«Q&Aã®å“è³ªå‘ä¸Šã‚’å›³ã‚Šã¾ã™ã€‚
"""
